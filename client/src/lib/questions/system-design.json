[
  {
    "id": "sd-1",
    "question": "Can you explain the Load Balancer strategy? When would you use Layer 4 vs Layer 7 load balancing?",
    "answer": "Load Balancing distributes traffic across multiple servers to ensure reliability and scalability.",
    "explanation": "A Load Balancer (LB) acts as a reverse proxy. \n\n**Layer 4 (Transport Layer)**: Distributes based on IP/Port. Fast, low overhead, but no context of content. Good for simple packet distribution.\n\n**Layer 7 (Application Layer)**: Inspects HTTP headers/content. Can route based on URL/cookies (e.g., /api to Service A, /static to Service B). More expensive but smarter.\n\n**Common Algorithms**:\n- **Round Robin**: Sequential.\n- **Least Connections**: Sends to server with fewest active connections.\n- **IP Hash**: Ensures a user always goes to the same server (sticky sessions).",
    "tags": [
      "infra",
      "scale",
      "networking"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "graph LR\n    User --> LB[Load Balancer]\n    LB -->|Layer 4| S1[\"Server 1<br/>IP:Port\"]\n    LB -->|Layer 7| S2[\"Server 2<br/>/api\"]\n    style LB fill:#fff,stroke:#000,color:#000",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "sd-2",
    "question": "What is Consistent Hashing and why is it critical for distributed caches?",
    "answer": "Consistent Hashing maps keys to a ring of nodes to minimize data movement when scaling.",
    "explanation": "In standard `hash(key) % N`, adding a node changes `N`, causing nearly ALL keys to remap (cache stampede).\n\n**Consistent Hashing** maps both servers and keys to a circle (0-360°). Keys map to the next server clockwise.\n\n**Benefit**: Adding/removing a node only affects the immediate neighbors (k/N keys move), not the whole cluster.\n\nUsed in: DynamoDB, Cassandra, Discord Ringpop.",
    "tags": [
      "hashing",
      "dist-sys",
      "caching"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "distributed-systems",
    "diagram": "\ngraph TD\n    subgraph Hash Ring\n    N1((Node 1)) --- N2((Node 2))\n    N2 --- N3((Node 3))\n    N3 --- N1\n    end\n    Key[Key K] -.->|Clockwise| N2\n    style N2 fill:#f00,stroke:#fff,color:#fff\n",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "sd-3",
    "question": "Explain the CAP Theorem. Can you really 'choose two'?",
    "answer": "CAP states a distributed store can only provide 2 of 3: Consistency, Availability, Partition Tolerance.",
    "explanation": "**Partition Tolerance (P)** is NOT optional in distributed systems (networks fail). \n\nSo the real choice is **CP vs AP** during a partition:\n\n- **CP (Consistency)**: Return error/timeout if data can't be synced. (e.g., Banking - better to fail than show wrong balance).\n- **AP (Availability)**: Return stale data but keep running. (e.g., Facebook Feed - better to show old posts than nothing).\n\n**PACELC Theorem** extends this: Else (when no partition), choose Latency (L) vs Consistency (C).",
    "tags": [
      "theory",
      "dist-sys",
      "database"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "distributed-systems",
    "diagram": "graph TD\n    CAP[CAP Theorem]\n    CAP --> C[Consistency]\n    CAP --> A[Availability]\n    CAP --> P[Partition Tolerance]\n    Note[Pick 2 of 3]\n    style Note fill:#f59e0b,stroke:#fff,color:#000",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "sd-4",
    "question": "How do you handle Database Sharding? What are the downsides?",
    "answer": "Sharding splits a large database into smaller, faster, easily managed parts called data shards.",
    "explanation": "**Horizontal Partitioning**: Splitting rows based on a Shard Key (e.g., UserID).\n\n**Downsides/Challenges**:\n1. **Resharding**: Hard to move data when a shard fills up.\n2. **Hotspot Key**: If Justin Bieber is on Shard 1, Shard 1 melts down.\n3. **Joins**: Cross-shard joins are expensive/impossible.\n\n**Mitigation**: Consistent Hashing, Virtual Nodes.",
    "tags": [
      "db",
      "scale",
      "architecture"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "database",
    "diagram": "\ngraph TD\n    App --> Router\n    Router -->|ID < 100| S1[(Shard 1)]\n    Router -->|ID > 100| S2[(Shard 2)]\n",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "sd-5",
    "question": "Design a Rate Limiter. What algorithms would you consider?",
    "answer": "Rate Limiting controls the amount of traffic sent or received by a network interface controller.",
    "explanation": "Prevents DoS attacks and resource starvation.\n\n**Algorithms**:\n1. **Token Bucket**: Tokens added at rate `r`. Request consumes token. Allows bursts.\n2. **Leaky Bucket**: Requests enter queue, processed at constant rate. Smooths traffic.\n3. **Fixed Window**: Count requests in 1s window. Edge case: 2x traffic at window boundary.\n4. **Sliding Window Log**: Precise but expensive (stores timestamps).\n\n**Implementation**: Redis (Lua scripts for atomicity).",
    "tags": [
      "security",
      "api",
      "algorithms"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "api-design",
    "diagram": "\ngraph LR\n    Req[Request] --> Check{Buckets Full?}\n    Check -->|No| Process[Process]\n    Check -->|Yes| Drop[429 Too Many Requests]\n",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "gh-31",
    "question": "What is Scalability in DevOps?",
    "answer": "Scalability is the capability of a system to handle a growing amount of work by adding resources to the system. There are two types of scaling:",
    "explanation": "Scalability is the capability of a system to handle a growing amount of work by adding resources to the system. There are two types of scaling:\n\n1. **Vertical Scaling (Scale Up):**\n- Adding more power to existing resources\n- Example: Upgrading CPU/RAM\n\n2. **Horizontal Scaling (Scale Out):**\n- Adding more resources\n- Example: Adding more servers",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "\ngraph TD\n    subgraph Vertical\n    S1[Small] --> S2[Large]\n    end\n    subgraph Horizontal\n    H1[Server] --- H2[Server] --- H3[Server]\n    end\n",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "gh-32",
    "question": "What is High Availability?",
    "answer": "High Availability (HA) is a characteristic of a system that aims to ensure an agreed level of operational performance, usually uptime, for a higher th...",
    "explanation": "High Availability (HA) is a characteristic of a system that aims to ensure an agreed level of operational performance, usually uptime, for a higher than normal period.\n\nKey components:\n1. **Redundancy:**\n- Multiple instances\n- No single point of failure\n\n2. **Monitoring:**\n- Health checks\n- Automated failover\n\n3. **Load Balancing:**\n- Traffic distribution\n- Resource optimization",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "\ngraph TD\n    LB[Load Balancer] --> S1[Server 1]\n    LB --> S2[Server 2]\n    S1 -.->|Failover| S2\n",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "gh-33",
    "question": "What is Load Balancing?",
    "answer": "Load Balancing is the process of distributing network traffic across multiple servers to ensure no single server bears too much demand.",
    "explanation": "Load Balancing is the process of distributing network traffic across multiple servers to ensure no single server bears too much demand.\n\nCommon Load Balancing algorithms:\n1. **Round Robin**\n2. **Least Connections**\n3. **IP Hash**\n4. **Weighted Round Robin**\n5. **Resource-Based**\n\nExample of Nginx Load Balancer configuration:\n```nginx\nhttp {\nupstream backend {\nserver backend1.example.com;\nserver backend2.example.com;\nserver backend3.example.com;\n}\n\nserver {\nlisten 80;\nlocation / {\nproxy_pass http://backend;\n}\n}\n}\n```",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "gh-34",
    "question": "What is Auto Scaling?",
    "answer": "Auto Scaling is a feature that automatically adjusts the number of compute resources based on the current demand.",
    "explanation": "Auto Scaling is a feature that automatically adjusts the number of compute resources based on the current demand.\n\nKey concepts:\n1. **Scaling Policies:**\n- Target tracking\n- Step scaling\n- Simple scaling\n\n2. **Metrics:**\n- CPU utilization\n- Memory usage\n- Request count\n- Custom metrics\n\nExample of AWS Auto Scaling configuration:\n```yaml\nAutoScalingGroup:\nMinSize: 1\nMaxSize: 10\nDesiredCapacity: 2\nHealthCheckType: ELB\nHealthCheckGracePeriod: 300\nLaunchTemplate:\nLaunchTemplateId: !Ref LaunchTemplate\nVersion: !GetAtt LaunchTemplate.LatestVersionNumber\n```",
    "tags": [
      "scale",
      "ha"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "\ngraph LR\n    Metrics[Metrics] --> ASG[Auto Scaling]\n    ASG -->|Scale Out| Add[Add Instances]\n    ASG -->|Scale In| Remove[Remove Instances]\n",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "sy-132",
    "question": "Design a distributed rate limiting system that can handle 1M+ requests per second across multiple data centers while maintaining consistency and low latency. How would you handle burst traffic, different rate limiting algorithms (token bucket, sliding window), and ensure fair distribution across users?",
    "answer": "Use distributed token bucket with Redis Cluster, consistent hashing for user distribution, and local caching with periodic sync for low latency.",
    "explanation": "## Distributed Rate Limiting System Design\n\n### Core Components\n\n**1. Rate Limiting Algorithms**\n- **Token Bucket**: Best for burst handling, allows temporary spikes\n- **Sliding Window**: More accurate but computationally expensive\n- **Fixed Window**: Simple but can cause boundary issues\n\n**2. Architecture Overview**\n- **API Gateway Layer**: First line of defense with local rate limiting\n- **Distributed Cache**: Redis Cluster for shared state across regions\n- **Rate Limit Service**: Dedicated microservice for complex logic\n- **Configuration Service**: Dynamic rule updates without deployment\n\n### Implementation Strategy\n\n**Local + Distributed Hybrid Approach:**\n```\n1. Local cache (99% of requests) - sub-millisecond latency\n2. Periodic sync with distributed store (every 100ms)\n3. Fallback to distributed check for edge cases\n```\n\n**Data Distribution:**\n- Consistent hashing for user → shard mapping\n- Replication factor of 3 for high availability\n- Cross-region replication with eventual consistency\n\n**Handling Scale:**\n- Partition by user ID hash\n- Use Lua scripts in Redis for atomic operations\n- Implement circuit breakers for Redis failures\n- Local rate limiting as fallback\n\n### Advanced Features\n\n**Burst Handling:**\n- Token bucket with configurable burst capacity\n- Adaptive rate limiting based on system load\n- Priority queues for different user tiers\n\n**Fairness & Anti-Gaming:**\n- Per-user quotas with spillover pools\n- Detect and penalize abusive patterns\n- Implement jitter to prevent thundering herd\n\n**Monitoring & Observability:**\n- Real-time metrics on rate limit hits\n- Distributed tracing for debugging\n- Alerting on unusual traffic patterns",
    "tags": [
      "api",
      "rest"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "api-design",
    "diagram": "graph TD\n    A[Client Requests] --> B[Load Balancer]\n    B --> C[API Gateway Cluster]\n    C --> D[Local Rate Limiter]\n    D --> E{Within Local Limit?}\n    E -->|Yes| F[Process Request]\n    E -->|No| G[Check Distributed Store]\n    G --> H[Redis Cluster]\n    H --> I[Rate Limit Service]\n    I --> J{Within Global Limit?}\n    J -->|Yes| K[Update Counters]\n    J -->|No| L[Reject Request]\n    K --> F\n    L --> M[Return 429]\n    \n    N[Config Service] --> O[Rate Limit Rules]\n    O --> C\n    O --> I\n    \n    P[Monitoring] --> Q[Metrics Collection]\n    Q --> R[Alerting]\n    \n    H --> S[Cross-Region Sync]\n    S --> T[Other Data Centers]",
    "lastUpdated": "2025-12-12T09:07:04.188Z"
  },
  {
    "id": "sy-137",
    "question": "Design a distributed system that provides exactly-once processing guarantees for event streams with out-of-order delivery and network partitions. How would you handle idempotency, deduplication, and causal consistency across multiple processing nodes?",
    "answer": "Use vector clocks for causal ordering, deterministic IDs for deduplication, and idempotent processors with write-ahead logs.",
    "explanation": "This is an advanced distributed systems design problem that combines several complex concepts:\n\n## Core Challenges\n1. **Exactly-once semantics**: Prevent duplicate processing while ensuring no events are lost\n2. **Out-of-order handling**: Events may arrive in different orders than sent\n3. **Network partitions**: System must remain consistent during partial failures\n4. **Causal consistency**: Maintain logical relationships between related events\n\n## Architecture Components\n\n### 1. Event Ingestion Layer\n- **Vector Clocks**: Attach to each event to track causal relationships\n- **Deterministic Event IDs**: Use content-based hashing + timestamp for deduplication\n- **Partitioning Strategy**: Hash-based sharding with consistent hashing\n\n### 2. Processing Layer\n- **Idempotent Processors**: Design state changes to be repeatable\n- **Write-Ahead Logs**: Record intent before execution for recovery\n- **Checkpointing**: Periodic state snapshots for fault tolerance\n\n### 3. Coordination Layer\n- **Raft Consensus**: For metadata and configuration management\n- **Gossip Protocol**: Disseminate vector clock updates\n- **Anti-entropy Mechanisms**: Detect and repair inconsistencies\n\n### 4. Storage Layer\n- **Multi-version Concurrency Control (MVCC)**: Handle concurrent access\n- **Compaction**: Remove obsolete versions while preserving causality\n- **Replication**: Quorum-based writes with read repair\n\n## Key Algorithms\n\n### Deduplication Strategy\n```python\ndef is_duplicate(event_id, processed_events):\n    if event_id in processed_events:\n        return True\n    # Check bloom filter for quick negative lookup\n    if bloom_filter.might_contain(event_id):\n        # Verify in persistent storage\n        return storage.contains(event_id)\n    return False\n```\n\n### Causal Ordering\n- Compare vector clocks to determine event ordering\n- Buffer events until causal dependencies are satisfied\n- Use topological sorting for dependency resolution\n\n### Failure Recovery\n- Replay from last checkpoint using write-ahead logs\n- Rebuild vector clock state from persistent storage\n- Coordinate with other nodes for consistency verification\n\n## Trade-offs\n- **Latency vs Consistency**: Vector clocks add overhead but ensure correctness\n- **Storage vs Performance**: MVCC increases storage but enables concurrency\n- **Complexity vs Reliability**: Sophisticated coordination improves fault tolerance\n\nThis design demonstrates mastery of distributed systems concepts including consensus algorithms, causal consistency, fault tolerance, and exactly-once processing semantics.",
    "tags": [
      "dist-sys",
      "architecture"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "distributed-systems",
    "diagram": "graph TD\n    A[Client] --> B[Event Ingestion]\n    B --> C[Vector Clock Attachment]\n    C --> D[Deterministic ID Generation]\n    D --> E[Partition Router]\n    E --> F[Processing Node 1]\n    E --> G[Processing Node 2]\n    E --> H[Processing Node N]\n    F --> I[Idempotent Processor]\n    G --> J[Idempotent Processor]\n    H --> K[Idempotent Processor]\n    I --> L[Write-Ahead Log]\n    J --> M[Write-Ahead Log]\n    K --> N[Write-Ahead Log]\n    L --> O[MVCC Storage]\n    M --> O\n    N --> O\n    O --> P[Replication Layer]\n    P --> Q[Raft Consensus Group]\n    F --> R[Gossip Protocol]\n    G --> R\n    H --> R\n    R --> S[Vector Clock Sync]\n    Q --> T[Configuration Manager]\n    S --> U[Anti-entropy Repair]",
    "lastUpdated": "2025-12-12T09:36:23.632Z"
  },
  {
    "id": "sy-138",
    "question": "Design a distributed rate limiting system that can handle 10M requests per minute across 100+ microservices with different rate limit policies per service and API key.",
    "answer": "Use token bucket algorithm with Redis cluster, local caching, and hierarchical rate limiting (global + per-service + per-key).",
    "explanation": "# Distributed Rate Limiting System Design\n\n## Core Requirements\n- 10M requests/minute throughput\n- Multiple rate limit policies per service\n- Per-API key limits\n- 99.9% availability\n- Sub-10ms latency\n\n## Architecture Components\n\n### 1. Rate Limiting Engine\n- **Token Bucket Algorithm**: Flexible burst handling\n- **Sliding Window**: Time-based accuracy\n- **Policy Engine**: Dynamic rule evaluation\n\n### 2. Storage Layer\n- **Redis Cluster**: Primary counter storage\n- **Local Cache**: LRU for frequently accessed keys\n- **Persistent Storage**: PostgreSQL for policy configuration\n\n### 3. Distribution Strategy\n- **Consistent Hashing**: Even key distribution\n- **Replication**: Multi-master Redis setup\n- **Sharding**: Key-based partitioning\n\n## Key Design Patterns\n\n### Hierarchical Rate Limiting\n1. **Global Limits**: Platform-wide protection\n2. **Service Limits**: Per-microservice constraints\n3. **API Key Limits**: User-specific restrictions\n\n### Performance Optimizations\n- **Batch Processing**: Redis MGET/MSET operations\n- **Async Updates**: Fire-and-forget counter increments\n- **Pre-aggregation**: Local batching before sync\n\n### Failure Handling\n- **Graceful Degradation**: Fallback to local-only limiting\n- **Circuit Breaker**: Fail-fast for Redis outages\n- **Rate Limit Escalation**: Progressive restriction\n\n## Implementation Considerations\n\n### Synchronization\n- **Atomic Operations**: Redis INCR with expiration\n- **Clock Drift**: NTP synchronization\n- **Consistent Window**: Aligned time boundaries\n\n### Scalability\n- **Horizontal Scaling**: Add Redis nodes\n- **Geographic Distribution**: Edge caching\n- **Load Distribution**: Smart client routing\n\n### Monitoring & Observability\n- **Real-time Metrics**: Prometheus integration\n- **Alerting**: Rate limit breach detection\n- **Audit Trail**: Policy change tracking",
    "tags": [
      "api",
      "rest"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "api-design",
    "diagram": "graph TD\n    A[Client Request] --> B[API Gateway]\n    B --> C[Rate Limiter Service]\n    C --> D{Local Cache Check}\n    D -->|Hit| E[Return Decision]\n    D -->|Miss| F[Redis Cluster]\n    F --> G[Policy Engine]\n    G --> H[Rate Limit Algorithm]\n    H --> I[Update Local Cache]\n    I --> E\n    E --> J{Allow?}\n    J -->|Yes| K[Forward to Service]\n    J -->|No| L[Return 429]\n    \n    subgraph \"Redis Cluster\"\n        F1[Shard 1]\n        F2[Shard 2]\n        F3[Shard N]\n    end\n    \n    subgraph \"Policy Store\"\n        G1[Global Policies]\n        G2[Service Policies]\n        G3[API Key Policies]\n    end\n    \n    G --> G1\n    G --> G2\n    G --> G3",
    "lastUpdated": "2025-12-12T09:36:34.140Z"
  },
  {
    "id": "sy-139",
    "question": "Design a rate limiting system for a multi-tenant API that supports burst capacity with token bucket algorithm, distributed coordination, and dynamic tenant-specific policies",
    "answer": "Distributed token bucket with Redis-backed state, tenant-specific rate configs, and local caches for performance",
    "explanation": "This system needs to handle multiple tenants with different rate limits, support burst capacity through token buckets, ensure coordination across multiple API instances, and provide dynamic policy updates.\n\nKey components:\n- **Token Bucket Algorithm**: Each tenant has a bucket with capacity (burst) and refill rate. Tokens are added at configured rate, requests consume tokens.\n- **Distributed State**: Redis stores current token counts and last refill timestamps for each tenant, ensuring consistency across instances.\n- **Local Caching**: Each API instance maintains a local cache of token counts with TTL to reduce Redis calls, using optimistic updates.\n- **Policy Management**: Dynamic rate limit configuration stored in database, propagated through Redis pub/sub.\n- **Fallback**: When Redis unavailable, fall back to local bucket with reduced capacity to prevent service interruption.\n\nPerformance considerations:\n- Pipeline Redis operations for batch updates\n- Use Lua scripts for atomic token operations\n- Implement write-back caching for burst scenarios\n- Separate hot path (rate check) from policy updates\n\nChallenges addressed:\n- Race conditions in distributed environment\n- Clock synchronization issues\n- Graceful degradation during failures\n- Tenant isolation and fairness",
    "tags": [
      "api",
      "rest"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "api-design",
    "diagram": "graph TD\n    A[Client Request] --> B{Rate Limiter Service}\n    B --> C[Local Cache Check]\n    C -->|Hit| D[Consume Local Tokens]\n    C -->|Miss| E[Redis Token Check]\n    E -->|Available| F[Consume Redis Tokens]\n    E -->|Limited| G[Reject - 429]\n    D --> H[Update Local Cache Async]\n    F --> I[Update Local Cache]\n    H --> J[Forward to API]\n    I --> J\n    G --> K[Return Rate Limit Headers]\n    J --> L[Response]\n    M[Policy Manager] --> N[Redis Pub/Sub]\n    N --> O[Update Local Config]\n    O --> B",
    "lastUpdated": "2025-12-12T09:36:49.367Z"
  },
  {
    "id": "sy-140",
    "question": "Design a rate limiting service that can handle 10 million requests per second with distributed consistency across multiple data centers. The service should support multiple rate limiting strategies (token bucket, sliding window, fixed window) and provide sub-millisecond latency. How would you architect this to handle bursts, prevent thundering herd problems, and ensure accurate global rate limits?",
    "answer": "Use Redis Cluster with Consistent Hashing + Local Caching + Adaptive Rate Limiting with Hierarchical Rate Limiting (user → API → global).",
    "explanation": "## Architecture Overview\n\n**Core Components:**\n1. **Rate Limiting Engine** - Pluggable strategy pattern supporting token bucket, sliding window, and fixed window algorithms\n2. **Distributed Cache Layer** - Redis Cluster with consistent hashing for horizontal scaling\n3. **Local Cache Tier** - L1 cache with write-through to reduce Redis load\n4. **Configuration Service** - Dynamic rule management with hot-reloading\n5. **Metrics & Analytics** - Real-time monitoring and alerting\n\n**Key Design Decisions:**\n\n### 1. Hierarchical Rate Limiting\n- **User Level**: Per-user quotas (e.g., 1000 req/min)\n- **API Level**: Per-endpoint limits (e.g., 100 req/min)\n- **Global Level**: System-wide protection (e.g., 10M req/s)\n\n### 2. Multi-Level Caching Strategy\n- **L1 Cache**: In-memory with 1-second TTL for 90% of requests\n- **L2 Cache**: Redis Cluster with consistent hashing\n- **Write-through**: Updates propagate to both levels\n\n### 3. Burst Handling\n- **Token Bucket**: Allows controlled bursts\n- **Credit System**: Accumulates unused capacity\n- **Priority Queues**: VIP users get preferential treatment\n\n### 4. Thundering Herd Prevention\n- **Request Coalescing**: Batch requests for same key\n- **Exponential Backoff**: Adaptive retry with jitter\n- **Circuit Breakers**: Fail-fast during overload\n\n### 5. Global Consistency\n- **Vector Clocks**: Resolve conflicts across data centers\n- **Gossip Protocol**: Sync rate limit state\n- **Eventual Consistency**: Acceptable for rate limiting\n\n### 6. Performance Optimizations\n- **Connection Pooling**: Reuse Redis connections\n- **Pipelining**: Batch Redis operations\n- **Compression**: Reduce network overhead\n- **Async Processing**: Non-blocking I/O\n\n### 7. Monitoring & Alerting\n- **Real-time Dashboards**: Rate limit utilization\n- **Anomaly Detection**: Unusual traffic patterns\n- **Auto-scaling**: Dynamic cluster sizing\n\n## Implementation Considerations\n\n**Data Model:**\n- Key: `rate_limit:{user_id}:{api_id}:{window}`\n- Value: `{count, last_reset, credits}`\n- TTL: Window duration + safety margin\n\n**Failure Modes:**\n- Redis unavailable: Fall back to local limits\n- Network partition: Permissive mode with logging\n- Cache stampede: Request deduplication\n\n**Scalability:**\n- Horizontal scaling with Redis Cluster\n- Geographic distribution with edge caching\n- Load balancing with consistent hashing",
    "tags": [
      "api",
      "rest"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "api-design",
    "diagram": "graph TD\n    A[Client Request] --> B[Load Balancer]\n    B --> C[Rate Limiting Service]\n    \n    C --> D{Local Cache Check}\n    D -->|Hit| E[Allow/Deny]\n    D -->|Miss| F[Distributed Cache]\n    \n    F --> G{Redis Cluster}\n    G --> H[Shard 1]\n    G --> I[Shard 2]\n    G --> J[Shard N]\n    \n    C --> K[Rate Limiting Engine]\n    K --> L[Token Bucket]\n    K --> M[Sliding Window]\n    K --> N[Fixed Window]\n    \n    C --> O[Configuration Service]\n    O --> P[Rate Limit Rules]\n    O --> Q[User Quotas]\n    \n    C --> R[Analytics Engine]\n    R --> S[Metrics Dashboard]\n    R --> T[Alert System]\n    \n    U[Data Center 1] --> G\n    V[Data Center 2] --> G\n    W[Data Center N] --> G\n    \n    G --> X[Gossip Protocol]\n    X --> Y[State Synchronization]\n    \n    style C fill:#e1f5fe\n    style G fill:#f3e5f5\n    style K fill:#e8f5e8",
    "lastUpdated": "2025-12-12T09:37:42.396Z"
  },
  {
    "id": "sy-141",
    "question": "Design a globally distributed serverless platform for real-time collaborative document editing with offline support and conflict resolution. How would you handle data consistency, versioning, and low-latency synchronization across AWS regions while maintaining sub-50ms response times?",
    "answer": "Use CRDTs for conflict resolution, WebSocket for real-time sync, edge locations for caching, DynamoDB Global Tables with multi-region replication.",
    "explanation": "## Architecture Overview\n\n### Data Model & Consistency\n- **CRDT-based Operational Transformation**: Each client tracks operations using Conflict-Free Replicated Data Types\n- **Document State Partitioning**: Split documents into chunks by section/paragraph for parallel processing\n- **Version Vectors**: Lamport timestamps for causality tracking across regions\n\n### Multi-Region Strategy\n- **Active-Active Regions**: Deploy Lambda functions in us-east-1, eu-west-1, ap-southeast-1\n- **DynamoDB Global Tables**: Multi-master replication with conflict-free write patterns\n- **CloudFront Edge Locations**: Cache hot documents with WebSocket support\n\n### Real-time Synchronization\n- **WebSocket Connections**: API Gateway with WebSocket protocol for bidirectional communication\n- **EventBridge**: Cross-region event propagation for coordination\n- **Local Caching**: ElastiCache Redis in each region for hot document state\n\n### Offline Support\n- **Service Worker**: IndexedDB for local storage and operation queuing\n- **Delta Synchronization**: Only transmit changes, not full document state\n- **Conflict Resolution**: CRDT automatically resolves merge conflicts when reconnecting\n\n### Performance Optimizations\n- **Edge Computing**: CloudFront Functions for document diff calculation at edge\n- **Connection Pooling**: WebSocket multiplexing to reduce connection overhead\n- **Smart Routing**: Route 53 latency-based routing to nearest region\n\n### Monitoring & Scaling\n- **Auto Scaling**: Lambda provisioned concurrency for predictable performance\n- **Real-time Metrics**: CloudWatch custom metrics for collaboration metrics\n- **Circuit Breakers**: Regional isolation to prevent cascade failures",
    "tags": [
      "infra",
      "scale"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "infrastructure",
    "diagram": "graph TD\n    A[Client Browser] -->|WebSocket| B[CloudFront Edge]\n    B -->|WebSocket| C[API Gateway WebSocket]\n    C --> D[Lambda Auth]\n    C --> E[Lambda Router]\n    E --> F[Lambda Document Handler]\n    E --> G[Lambda Sync Handler]\n    F --> H[DynamoDB Global Table]\n    G --> I[EventBridge Bus]\n    I --> J[Cross-Region EventBridge]\n    J --> K[Other Region Lambda]\n    F --> L[ElastiCache Redis]\n    K --> M[DynamoDB Replica]\n    A --> N[Service Worker]\n    N --> O[IndexedDB Storage]\n    P[Route 53] -->|Latency Routing| B\n    Q[CloudWatch] -->|Metrics| E",
    "lastUpdated": "2025-12-12T09:38:09.154Z"
  },
  {
    "id": "sy-144",
    "question": "Design a distributed rate limiting system that can handle 1M+ requests per second across multiple data centers while maintaining consistency and preventing thundering herd problems during cache misses.",
    "answer": "Use sliding window counters with Redis Cluster, consistent hashing, and circuit breakers with jittered backoff for cache miss protection.",
    "explanation": "## Architecture Components\n\n### 1. Distributed Counter Storage\n- **Redis Cluster** with consistent hashing for horizontal scaling\n- **Sliding window counters** using sorted sets with timestamps\n- **Multi-level caching**: L1 (local), L2 (regional), L3 (global)\n\n### 2. Rate Limiting Algorithm\n```\nkey = user_id:window_start_time\ncount = ZCOUNT key (now-window_size) now\nif count < limit:\n  ZADD key now unique_request_id\n  EXPIRE key window_size\n  return ALLOW\nelse:\n  return DENY\n```\n\n### 3. Consistency Strategy\n- **Eventually consistent** across regions (acceptable for rate limiting)\n- **Strong consistency** within data center using Redis transactions\n- **Conflict resolution**: Last-writer-wins with vector clocks\n\n### 4. Thundering Herd Prevention\n- **Circuit breaker pattern** with exponential backoff\n- **Jittered cache refresh** (random 10-30% of TTL)\n- **Probabilistic early expiration** to spread load\n- **Request coalescing** for identical cache misses\n\n### 5. High Availability\n- **Multi-master Redis setup** with cross-region replication\n- **Graceful degradation**: Allow requests when cache unavailable\n- **Health checks** and automatic failover\n- **Rate limit approximation** during partial failures",
    "tags": [
      "dist-sys",
      "architecture"
    ],
    "difficulty": "advanced",
    "channel": "system-design",
    "subChannel": "distributed-systems",
    "diagram": "graph TD\n    A[Client Request] --> B[Load Balancer]\n    B --> C[Rate Limiter Service]\n    C --> D{Local Cache Hit?}\n    D -->|Yes| E[Check Counter]\n    D -->|No| F[Circuit Breaker]\n    F -->|Open| G[Allow Request]\n    F -->|Closed| H[Redis Cluster]\n    H --> I[Sliding Window Counter]\n    I --> J{Under Limit?}\n    J -->|Yes| K[Increment Counter]\n    J -->|No| L[Reject Request]\n    K --> M[Update Local Cache]\n    M --> N[Forward Request]\n    E --> J\n    \n    subgraph Redis Cluster\n        H1[Redis Master 1]\n        H2[Redis Master 2]\n        H3[Redis Master 3]\n        H1 -.-> H2\n        H2 -.-> H3\n        H3 -.-> H1\n    end\n    \n    subgraph Multi-DC\n        DC1[Data Center 1]\n        DC2[Data Center 2]\n        DC1 -.->|Async Replication| DC2\n    end",
    "lastUpdated": "2025-12-12T10:05:21.929Z"
  }
]