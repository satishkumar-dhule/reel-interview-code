{
  "id": "sy-132",
  "question": "Design a distributed rate limiting system that can handle 1M+ requests per second across multiple data centers while maintaining consistency and low latency. How would you handle burst traffic, different rate limiting algorithms (token bucket, sliding window), and ensure fair distribution across users?",
  "answer": "Use distributed token bucket with Redis Cluster, consistent hashing for user distribution, and local caching with periodic sync for low latency.",
  "explanation": "## Distributed Rate Limiting System Design\n\n### Core Components\n\n**1. Rate Limiting Algorithms**\n- **Token Bucket**: Best for burst handling, allows temporary spikes\n- **Sliding Window**: More accurate but computationally expensive\n- **Fixed Window**: Simple but can cause boundary issues\n\n**2. Architecture Overview**\n- **API Gateway Layer**: First line of defense with local rate limiting\n- **Distributed Cache**: Redis Cluster for shared state across regions\n- **Rate Limit Service**: Dedicated microservice for complex logic\n- **Configuration Service**: Dynamic rule updates without deployment\n\n### Implementation Strategy\n\n**Local + Distributed Hybrid Approach:**\n```\n1. Local cache (99% of requests) - sub-millisecond latency\n2. Periodic sync with distributed store (every 100ms)\n3. Fallback to distributed check for edge cases\n```\n\n**Data Distribution:**\n- Consistent hashing for user â†’ shard mapping\n- Replication factor of 3 for high availability\n- Cross-region replication with eventual consistency\n\n**Handling Scale:**\n- Partition by user ID hash\n- Use Lua scripts in Redis for atomic operations\n- Implement circuit breakers for Redis failures\n- Local rate limiting as fallback\n\n### Advanced Features\n\n**Burst Handling:**\n- Token bucket with configurable burst capacity\n- Adaptive rate limiting based on system load\n- Priority queues for different user tiers\n\n**Fairness & Anti-Gaming:**\n- Per-user quotas with spillover pools\n- Detect and penalize abusive patterns\n- Implement jitter to prevent thundering herd\n\n**Monitoring & Observability:**\n- Real-time metrics on rate limit hits\n- Distributed tracing for debugging\n- Alerting on unusual traffic patterns",
  "diagram": "graph TD\n    A[Client Requests] --> B[Load Balancer]\n    B --> C[API Gateway Cluster]\n    C --> D[Local Rate Limiter]\n    D --> E{Within Local Limit?}\n    E -->|Yes| F[Process Request]\n    E -->|No| G[Check Distributed Store]\n    G --> H[Redis Cluster]\n    H --> I[Rate Limit Service]\n    I --> J{Within Global Limit?}\n    J -->|Yes| K[Update Counters]\n    J -->|No| L[Reject Request]\n    K --> F\n    L --> M[Return 429]\n    \n    N[Config Service] --> O[Rate Limit Rules]\n    O --> C\n    O --> I\n    \n    P[Monitoring] --> Q[Metrics Collection]\n    Q --> R[Alerting]\n    \n    H --> S[Cross-Region Sync]\n    S --> T[Other Data Centers]",
  "difficulty": "advanced",
  "tags": [
    "api",
    "rest"
  ],
  "lastUpdated": "2025-12-12T09:07:04.188Z"
}